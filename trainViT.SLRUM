#!/bin/bash
#SBATCH --job-name=phytoViT
#SBATCH --output=logs/vit_train.out
#SBATCH --error=logs/vit_train.err
#SBATCH --time=48:00:00               # Maximum runtime of 24 hours (adjust as needed)
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=2             # Use 8 CPU cores per task
#SBATCH --mem=32G                     # Request 32GB of system memory
#SBATCH --mail-type=END,FAIL
#SBATCH --mail-user=pcdaniel@ucsc.edu
#SBATCH --partition=96x24gpu4                 # Request 1 GPU

# This SLURM script is configured for training a ViT model on 1.2 million images (~18GB zipped data).
# Adjust the resources (time, CPUs, memory) if your experiments require more or less.

# Load any necessary modules (e.g., CUDA)
module load miniconda3
module load cuda/12.6              # Adjust CUDA version if needed

# Activate your conda environment
conda activate trainViT

# Run the training script with a configuration file that sets the training options.
export CUDA_VISIBLE_DEVICES=-1
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

python src/train_ViT.py --config experiments/config_hb.json

# Testing GPU Access
#python src/tensorflow-load-test.py

